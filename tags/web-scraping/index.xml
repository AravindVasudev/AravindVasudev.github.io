<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>web scraping on Yet another programmer's blog</title><link>/tags/web-scraping/</link><description>Recent content in web scraping on Yet another programmer's blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 14 Jan 2017 02:51:00 +0530</lastBuildDate><atom:link href="/tags/web-scraping/index.xml" rel="self" type="application/rss+xml"/><item><title>Web Scraping 101 (part 2): Build an Anna University Result Scraper</title><link>/2017/web-scraping-101-part2/</link><pubDate>Sat, 14 Jan 2017 02:51:00 +0530</pubDate><guid>/2017/web-scraping-101-part2/</guid><description>This is the follow-up to Web Scraping 101: Build a simple web scraper using PHP. If you haven&amp;rsquo;t seen it yet, I&amp;rsquo;d highly recommend you to read that before continuing.
In this tutorial, we will be building a simple web scraper that extracts the result from Anna University&amp;rsquo;s website. This tutorial is strictly for educational purposes.
AU Scraper We are going to do this in 4 simple steps:
Step 1: read the website and create the DOM Anna University provides a nice little endpoint using which we can view our result by sending a GET Request.</description></item><item><title>Web Scraping 101 : Build a simple web scraper using PHP</title><link>/2017/web-scraping-101/</link><pubDate>Fri, 13 Jan 2017 12:48:00 +0530</pubDate><guid>/2017/web-scraping-101/</guid><description>There are times when we want to extract data from a website. In most cases, you are provided with an API, but that&amp;rsquo;s not always plausible. So, when a website does not provide an API, the only way to get the data from the website is to scrape it off yourself.
In this tutorial, we are going to build a simple scraper using PHP to extract data from Wikipedia (I&amp;rsquo;d highly recommend you to use Wikipedia API over this.</description></item></channel></rss>